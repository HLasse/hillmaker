{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hillmaker - OO design ideas\n",
    "\n",
    "https://github.com/misken/hillmaker/tree/develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO - Add material from previous explainer notebooks that covers horizon, warmup, use of CLI details and more.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall application design goals and objectives\n",
    "\n",
    "- should be easy to run a scenario and get all the standard outputs\n",
    "- scenario specific settings should be persistable as something like a json file\n",
    "- should be possible to generate only outputs wanted\n",
    "- should have a CLI\n",
    "- should be importable so that it can be used from notebook or other custom Python scripts\n",
    "- be nice to have a GUI for non-technie users\n",
    "- should be easy to explore multiple scenarios\n",
    "- global and scenario specific settings can be managed through settings files, command line args or function args\n",
    "- current occupancy, arrival and departure stats all still desirable\n",
    "- los summary would be nice\n",
    "- outputs should be in formats that lend themselves to further analysis and reporting such as csvs for the occ stats (bydatetime and summary), standard graphic file formats, perhaps JSON for los summary and occ stats\n",
    "- dataset profiling should be done to identify potential issues with horizon effects, warmup effects, missing data periods, or other anomolies.\n",
    "\n",
    "\n",
    "Should hillmaker be redesigned as an OO based application?\n",
    "\n",
    "- does OO design make for a better analyst experience? For example, does OO make it easier to create and manage a bunch of scenarios in which each is a separate hillmaker run? OO would make it easier to document scenarios through their settings (e.g. as json file).\n",
    "- does OO lead to potential performance gains by making it easier to only run the parts we want to run. For example, maybe we don't want individual day of week plots.\n",
    "- right now hillmaker is an (almost) all or nothing experience with each run standing alone. \n",
    "- OO would likely be better for those using hillmaker programmatically. \n",
    "- no matter what the design, there will always be a CLI.\n",
    "- not sure how OO or not affects GUI dev\n",
    "\n",
    "How should hillmaker be redesigned as an OO based application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 1 - overall and by patient type summaries\n",
    "\n",
    "Patients flow through a short stay unit for a variety of procedures, tests or therapies. Let's assume patients can be classified into one of five categories of patient types: ART (arterialgram), CAT (post cardiac-cath), MYE (myelogram), IVT (IV therapy), and OTH (other). From one of our hospital information systems we were able to get raw data about the entry and exit times of each patient and exported the data to a csv file. We call each row of such data a *stop* (as in, the patient stopped here for a while). \n",
    "\n",
    "- We want to generate summaries of occupancy as well as arrivals and discharges to go into a summary report for hospital administration. \n",
    "- We want these overall and by patient type. \n",
    "- We also want LOS summaries by patient type. \n",
    "- Volume and occupancy trends over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from IPython.display import Image\n",
    "\n",
    "from datetime import datetime, date\n",
    "from typing import Dict, List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssu_stopdata = '../data/ShortStay.csv'\n",
    "ssu_stops_df = pd.read_csv(ssu_stopdata, parse_dates=['InRoomTS','OutRoomTS'])\n",
    "ssu_stops_df.info() # Check out the structure of the resulting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssu_stops_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An OO version of hillmaker (0.5.0)\n",
    "\n",
    "This is a work in progress and just wanted to share some early ideas. To summarize:\n",
    "\n",
    "- added a `Scenario` class which has methods for running hillmaker (`make_hills()`) and for retrieving plots and dataframes from the results dictionary (`get_plot()`, `get_summary_df()`, and `get_bydatetime_df()`). \n",
    "- the plots and dataframes produced by `make_hills` are stored in a dictionary called `hills` that is an attribute of the `Scenario` class\n",
    "- the methods of the `Scenario` class are just wrappers that call module level functions of the same name that do the actual work. By doing this, I haven't broken the existing hillmaker API - you can still call a `make_hills` function and pass in a bunch of key word arguments and run things. The `make_hills()` function returns a `hills` dictionary and `get_plot` and `get_*_df` functions can be used to extract plots and dataframes from `hills` in a simple way.\n",
    "- the `Scenario` class is actually a `pydantic` model which handles input validation.\n",
    "\n",
    "So, hillmaker can be used in either an objected oriented way or a via standard function calls. It also has (or will have) a CLI. For now, this lets us try it out and see what makes the most sense for future development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example 1 - the OO approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hillmaker as hm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a collection of inputs that we'll use to create a scenario. Notice I purposely set one of the input dates to a string and the other to a `Timestamp` just to show that the `pydantic` model can handle the automatic transformation for us to a `datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required inputs\n",
    "scenario_name = 'ssu_1'\n",
    "stops_df = ssu_stops_df\n",
    "in_field_name = 'InRoomTS'\n",
    "out_field_name = 'OutRoomTS'\n",
    "start_date = '1996-01-01'\n",
    "end_date = pd.Timestamp('9/30/1996')\n",
    "\n",
    "# Optional inputs\n",
    "\n",
    "cat_field_name = 'PatType'\n",
    "verbosity = 1 # INFO level logging\n",
    "output_path = './output'\n",
    "bin_size_minutes = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a `Scenario` class that is a Pydantic model. It handles a bunch of type constraints, validation, and default values. What does the `Scenario` class look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hm.Scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create scenarios a few different ways.\n",
    "\n",
    "- instantiate an instance of `Scenario` by passing in keyword args\n",
    "- if the args are in a dict, can use dictionary unpacking to do the same\n",
    "- there's a `create_scenario` function in the `utils` module that can take any of a dict, a TOML path or keyword args and returns a `Scenario` object (precedence is in the reverse order - kwargs get the final say)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new scenario with keyword arguments\n",
    "\n",
    "You can create an instance of `Scenario` by passing in keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1 = hm.Scenario(scenario_name=scenario_name, \n",
    "                         stops_df=stops_df,\n",
    "                         in_field=in_field_name,\n",
    "                         out_field=out_field_name,\n",
    "                         start_analysis_dt=start_date,\n",
    "                         end_analysis_dt=end_date,\n",
    "                         cat_field=cat_field_name,\n",
    "                         output_path=Path('./output'),\n",
    "                         verbosity=verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint(scenario_1.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use pydantic's `model_dump` function to create dictionary from a pydantic model. I'll do that and make a few changes and create a new scenario from the modified dict using dictionary unpacking to pass in the keyword arguments to `Scenario`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump pydantic model to dict (could wrap this with a to_dict() method\n",
    "scenario_2_dict = scenario_1.model_dump()\n",
    "\n",
    "# Make some changes\n",
    "scenario_2_dict['scenario_name'] = 'ssu_2'\n",
    "scenario_2_dict['bin_size_minutes'] = 30\n",
    "\n",
    "# Make a new scenario using dictionary unpacking\n",
    "scenario_2 = hm.Scenario(**scenario_2_dict)\n",
    "\n",
    "pprint(scenario_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the scenario objects are really just a Python class, attributes can be get and set in the usual way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new scenario with a TOML config file\n",
    "\n",
    "To use a TOML configuration file to create a scenario, we can use the `create_scenario` function in the `utils` module.\n",
    "Notice here that instead of specifying a pandas `DataFrame`, we are specifiying a path to a csv file which will be read to create the stops `DataFrame`. It would be also possible to allow a string corresponding to the name of an existing `DataFrame` to be specified - we could use the `globals()[<string_name_of_dataframe>]` construct to access the actual object.\n",
    "\n",
    "Here's an example config file:\n",
    "\n",
    "```\n",
    "[scenario_data]\n",
    "scenario_name = \"ssu_3\"\n",
    "stop_data_csv = \"../data/ShortStay.csv\"\n",
    "\n",
    "[fields]\n",
    "in_field = \"InRoomTS\"\n",
    "out_field = \"OutRoomTS\"\n",
    "# Just remove the following line if no category field\n",
    "cat_field = \"PatType\"\n",
    "\n",
    "[analysis_dates]\n",
    "start_analysis_dt = 1996-01-01\n",
    "end_analysis_dt = 1996-09-30\n",
    "\n",
    "[settings]\n",
    "bin_size_minutes = 60\n",
    "verbosity = 1\n",
    "output_path = \"./output\"\n",
    "\n",
    "# Add any additional arguments here\n",
    "# Strings should be surrounded in double quotes\n",
    "# Floats and ints are specified in the normal way as values\n",
    "# Dates are specified as shown above\n",
    "\n",
    "# For arguments that take lists, the entries look\n",
    "# just like Python lists and following the other rules above\n",
    "\n",
    "# cats_to_exclude = [\"IVT\", \"OTH\"]\n",
    "# percentiles = [0.5, 0.8, 0.9]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = Path('ssu_3.toml')\n",
    "scenario_3 = hm.create_scenario(toml_path=config_file)\n",
    "print(scenario_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.bin_size_minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is convenient, it does mean that as the programmer, you can get around some of the validation checks that were already done. For example, `bin_size_minutes` must evenly divide into 1440. I can add code to revalidate the model before allowing `make_hills` to run but I'm not going to bother for now. The standard Python error system will catch bad things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad\n",
    "scenario_1.bin_size_minutes = 17\n",
    "\n",
    "# Set it back to a valid value\n",
    "scenario_1.bin_size_minutes = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new scenario using `create_scenario()` and a dictionary\n",
    "\n",
    "The `create_scenario` function also can take, as input, a dictionary of input arguments. Notice in the example below that I've used strings for the dates but I could just as well have used `datetime` or `TimeStamp` objects - anything that can be converted to a pandas `TimeStamp` is allowed. I've only included the required parameters and two optional parameters - `cat_field` and `bin_size_mins`.\n",
    "\n",
    "```\n",
    "scenario_4_dict = {\n",
    "    'scenario_name': 'ssu_4',\n",
    "    'stops_df': ssu_stops_df,\n",
    "    'in_field': 'InRoomTS',\n",
    "    'out_field': 'OutRoomTS',\n",
    "    'start_analysis_dt': '1996-01-01',\n",
    "    'end_analysis_dt': '1996-09-30',\n",
    "    'cat_field': 'PatType',\n",
    "    'bin_size_minutes': 60\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.create_scenario?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_4_dict = {\n",
    "    'scenario_name': 'ssu_4',\n",
    "    'stops_df': ssu_stops_df,\n",
    "    'in_field': 'InRoomTS',\n",
    "    'out_field': 'OutRoomTS',\n",
    "    'start_analysis_dt': '1996-01-01',\n",
    "    'end_analysis_dt': '1996-09-30',\n",
    "    'cat_field': 'PatType',\n",
    "    'bin_size_minutes': 60\n",
    "}\n",
    "\n",
    "scenario_4 = hm.create_scenario(params_dict=scenario_4_dict)\n",
    "print(scenario_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `create_scenario`, you can also include keyword arguments that will take precedence over those specified in either a TOML file or a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_5_dict = {\n",
    "    'scenario_name': 'ssu_5',\n",
    "    'stops_df': ssu_stops_df,\n",
    "    'in_field': 'InRoomTS',\n",
    "    'out_field': 'OutRoomTS',\n",
    "    'start_analysis_dt': '1996-01-01',\n",
    "    'end_analysis_dt': '1996-09-30',\n",
    "    'cat_field': 'PatType',\n",
    "    'bin_size_minutes': 60\n",
    "}\n",
    "\n",
    "scenario_5 = hm.create_scenario(params_dict=scenario_5_dict, \n",
    "                                export_all_week_plots=True, bin_size_minutes=30)\n",
    "print(scenario_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate hills by using the `make_hills` method of one of the scenario instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.make_hills()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the outputs get stored in the `hills` dictionary attribute. It's a nested dictionary and it can be cumbersome to pull out specific items. Later in this notebook we'll describe \"getter\" methods to make it easier to pull out specific plots or dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['bydatetime'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['bydatetime']['PatType_datetime'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries']['nonstationary'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries']['nonstationary']['PatType_dow_binofday'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries']['nonstationary']['PatType_dow_binofday']['occupancy'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['settings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving specific plots and/or DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously pointed out, it's clunky to have to traverse these dictionaries to pull out plots and dataframes. Seems like we'd want to be able to quickly view a specific plot or `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods `get_plot()` and `get_dataframe()` were added the `Scenario` class. These are actually just wrappers for module level functions `hills.get_plot()` and `hills.get_dataframe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.get_plot??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = scenario_1.get_plot('occupancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.get_plot('occ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.get_plot('departures', 'Mon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_2.get_summary_df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_summary_df = scenario_1.get_summary_df('o')\n",
    "occ_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_occ_summary_df = scenario_1.get_summary_df('o', by_category=False)\n",
    "overall_occ_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_stationary_occ_summary_df = scenario_1.get_summary_df('o', by_category=False, stationary=True)\n",
    "overall_stationary_occ_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting summary or datetime csv files\n",
    "\n",
    "Currently, if you use the `make_hills` method (or the `make_hills` legacy function - more on this below), you can use the following arguments to control exporting of plots and dataframes:\n",
    "\n",
    "```\n",
    "# Exporting dataframes\n",
    "export_bydatetime_csv : bool, optional\n",
    "       If True, bydatetime DataFrames are exported to csv files. Default is False.\n",
    "export_summaries_csv : bool, optional\n",
    "       If True, summary DataFrames are exported to csv files. Default is False.\n",
    "\n",
    "# Exporting plots       \n",
    "export_all_dow_plots : bool, optional\n",
    "   If True, day of week plots are exported for occupancy, arrival, and departure. Default is False.\n",
    "export_all_week_plots : bool, optional\n",
    "   If True, full week plots are exported for occupancy, arrival, and departure. Default is False.\n",
    " \n",
    "```\n",
    "\n",
    "It's an \"all or none\" kind of decision with respect to each argument. Of course, you can always use `get_plot` or `get_dataframe` and then manually export it yourself. See cell below.\n",
    "\n",
    "**QUESTION** What might an API look like that supported more fine grained control of plot and dataframe exporting but didn't rely on the user doing the manual kind of thing below?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the dataframe of interest\n",
    "overall_occ_summary_df = scenario_1.get_summary_df('o', by_category=False)\n",
    "\n",
    "# Create output filename with path\n",
    "export_path = Path('./output')\n",
    "file_summary_csv = 'scenario_1_occ.csv'\n",
    "csv_wpath = Path(export_path, file_summary_csv)\n",
    "\n",
    "# Export the dataframe\n",
    "overall_occ_summary_df.to_csv(csv_wpath, index=True, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing statistics with no plotting\n",
    "\n",
    "The default DOW and weekly plots can be supressed through key word arguments when creating a `Scenario` instance by setting `make_all_dow_plots=False` and `make_all_week_plots=False`.\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_ts = pd.Timestamp(start_date)\n",
    "scenario_6 = hm.Scenario(scenario_name=scenario_name, \n",
    "                         stops_df=stops_df,\n",
    "                         in_field=in_field_name,\n",
    "                         out_field=out_field_name,\n",
    "                         start_analysis_dt=start_date_ts,\n",
    "                         end_analysis_dt=start_date_ts + pd.Timedelta(90, 'd'),\n",
    "                         cat_field=cat_field_name,\n",
    "                         output_path=Path('./output'),\n",
    "                         verbosity=0,\n",
    "                         make_all_dow_plots=False,\n",
    "                         make_all_week_plots=False)\n",
    "\n",
    "scenario_6.make_hills()\n",
    "\n",
    "print(scenario_6.hills.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also added a `compute_hills_stats` method that just does the bydatetime and summary stats, but does NOT create plots or export anything. It populates the `hills` attribute (a dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_ts = pd.Timestamp(start_date)\n",
    "scenario_7 = hm.Scenario(scenario_name=scenario_name, \n",
    "                         stops_df=stops_df,\n",
    "                         in_field=in_field_name,\n",
    "                         out_field=out_field_name,\n",
    "                         start_analysis_dt=start_date_ts,\n",
    "                         end_analysis_dt=start_date_ts + pd.Timedelta(90, 'd'),\n",
    "                         cat_field=cat_field_name,\n",
    "                         output_path=Path('./output'),\n",
    "                         verbosity=0)\n",
    "\n",
    "scenario_7.compute_hills_stats()\n",
    "\n",
    "print(scenario_7.hills.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan is to add additional plot types and plotting related input arguments to allow better plot customization. For now, I've just added a function, `make_week_dow_plots()` to the `plotting` module that creates all of the DOW and weekly plots that are currently created. So, if you want, you can call `make_week_dow_plots()` after computing statistics with `compute_hills_stats` by passing in the resulting `hills` dictionary. **This feels kludgy in that the `scenario.hills` dict isn't updated which means that the `get_plot` method won't work.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_7_plots = hm.plotting.make_week_dow_plots(scenario_7, scenario_7.hills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_7_plots.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Just as with the dataframes, we need to design an API for fine grained plotting control.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example 2 - the non-OO approach\n",
    "\n",
    "This is just the way that `make_hills` has been used in recent versions of hillmaker. I wanted to keep this around as a \"legacy\" function that still works. The way I ended up doing it was to:\n",
    "\n",
    "- created a `legacy.make_hills()` function that creates a `Scenario` object from the user specified input arguments which...\n",
    "- then calls `hills.make_hills(<scenario object>)` to actually does the work\n",
    "\n",
    "By creating the legacy wrapper function, the inputs can be validated with the Pydantic `Scenario` model class. The user never knows that they are actually using a `Scenario` object and `hills.make_hills()` returns the same dictionary that gets stored in the `hills` attribute of a `Scenario` instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required inputs\n",
    "scenario_name = 'legacy_example_1'\n",
    "in_field_name = 'InRoomTS'\n",
    "out_field_name = 'OutRoomTS'\n",
    "start_date = '1996-01-01'\n",
    "end_date = pd.Timestamp('9/30/1996')\n",
    "\n",
    "# Optional inputs\n",
    "\n",
    "cat_field_name = 'PatType'\n",
    "verbosity = 1 # INFO level logging\n",
    "output_path = './output'\n",
    "bin_size_minutes = 60\n",
    "\n",
    "\n",
    "hills_legacy_example_1 = hm.make_hills(scenario_name=scenario_name, stops_df=ssu_stops_df,\n",
    "              in_field=in_field_name, out_field=out_field_name,\n",
    "              start_analysis_dt=start_date, end_analysis_dt=end_date,\n",
    "              cat_field=cat_field_name,\n",
    "              bin_size_minutes=bin_size_minutes,\n",
    "              output_path='./output', verbosity=verbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to get a plot we call the module level `get_plot` and pass in the hills dictionary. The `hills` dictionary contains a `'settings'` key that is used to store things needed for plots and dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hills_legacy_example_1['settings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = hm.get_plot(hills_legacy_example_1, 'o', 'week')\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example 3 - the CLI\n",
    "\n",
    "I updated some of the names of the input arguments to match the current arguments used by the `Scenario` model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hillmaker --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hillmaker --scenario_name cli_example_1 --stop_data_csv '../data/ShortStay.csv' \\\n",
    "--in_field 'InRoomTS' --out_field 'OutRoomTS' --cat_field 'PatType' \\\n",
    "--start_analysis_dt '1996-01-01' --end_analysis_dt '1996-09-30' \\\n",
    "--export_all_dow_plots --export_all_week_plots --output_path './output' --verbosity 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hm_oo]",
   "language": "python",
   "name": "conda-env-hm_oo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
