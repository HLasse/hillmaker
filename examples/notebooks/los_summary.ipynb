{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length of stay summary dev - hillmaker (v0.5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>WARNING</b> Numerous API and core code changes have happened to hillmaker recently and this notebook is specific to v0.5.x. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from IPython.display import Image\n",
    "\n",
    "import hillmaker as hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssu_stopdata = '../data/ShortStay.csv'\n",
    "stops_df = pd.read_csv(ssu_stopdata, parse_dates=['InRoomTS','OutRoomTS'])\n",
    "stops_df.info() # Check out the structure of the resulting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of stay summary\n",
    "\n",
    "We can precompute LOS during the pydantic model pre-processing step. Instead of storing it as a Timedelta, we could allow user to specify units for LOS summary (default = 'h') where the unit string codes are same as used for Timedelta conversions.\n",
    "\n",
    "https://en.wikipedia.org/wiki/ISO_8601#Durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 'hours'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "los_field_name = f'los_{units}'\n",
    "stops_df[los_field_name] = (stops_df['OutRoomTS'] - stops_df['InRoomTS']) / pd.Timedelta(1, units)\n",
    "stops_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to statistical summaries as shown below, it would be nice to have histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df.groupby(['PatType'])[los_field_name].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.groupby import DataFrameGroupBy\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_stats(group: DataFrameGroupBy,\n",
    "                  percentiles: Tuple[float] | List[float] = (0.25, 0.5, 0.75, 0.95, 0.99),\n",
    "                  stub: str = ''):\n",
    "    \"\"\"\n",
    "    Compute summary statistics on a pandas `DataFrameGroupBy` object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    group : pd.DataFrameGroupBy\n",
    "        The grouping is by category\n",
    "    percentiles : list or tuple of floats (e.g. [0.5, 0.75, 0.95]), optional\n",
    "        Which percentiles to compute. Default is (0.25, 0.5, 0.75, 0.95, 0.99)\n",
    "    stub : str\n",
    "        Used to create field names (e.g. '{stub}_mean')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict whose keys are '{stub}_{statistic}'. Dict values are `DataFrame` objects.\n",
    "\n",
    "    \"\"\"\n",
    "    stats = {stub + 'count': group.count(), stub + 'mean': group.mean(),\n",
    "             stub + 'min': group.min(),\n",
    "             stub + 'max': group.max(), 'stdev': group.std(), 'sem': group.sem(),\n",
    "             stub + 'var': group.var(), 'cv': group.std() / group.mean() if group.mean() > 0 else 0,\n",
    "             stub + 'skew': group.skew(), 'kurt': group.kurt()}\n",
    "\n",
    "    if percentiles is not None:\n",
    "        pctile_vals = group.quantile(percentiles)\n",
    "\n",
    "        for p in percentiles:\n",
    "            pctile_name = f'{stub}p{int(100 * p):d}'\n",
    "            stats[pctile_name] = pctile_vals[p]\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_field_grp = stops_df.groupby(['PatType'])\n",
    "occ_stats = cat_field_grp[los_field_name].apply(summary_stats)\n",
    "occ_stats.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to make nice looking tabular outputs? Similar to gtable in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Apply the default theme\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=stops_df, x=\"los_hours\", hue=\"PatType\", col=\"PatType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=stops_df, x=\"los_hours\", hue=\"PatType\", col=\"PatType\", kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=stops_df, x=\"los_hours\", hue=\"PatType\", col=\"PatType\", stat='density', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think to have a non-shared y-axis, you have to use the `FacetGrid` and `map` approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=stops_df, x=\"los_hours\", hue=\"PatType\", kind='ecdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=stops_df, x=\"los_hours\", hue=\"PatType\", kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=stops_df, x=\"PatType\", y=\"los_hours\", kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=stops_df, x=\"PatType\", y=\"los_hours\", kind=\"violin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=stops_df, x=\"PatType\", y=\"los_hours\", kind=\"boxen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=stops_df, x=\"PatType\", y=\"los_hours\", kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to change y-axis to be relative frequency instead of raw counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=stops_df, x=\"los_hours\", hue=\"PatType\", element=\"step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=stops_df, col=\"PatType\", sharex=False, sharey=False)\n",
    "g.map(sns.histplot, \"los_hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=stops_df, col=\"PatType\", sharex=False);\n",
    "g.map(sns.histplot, \"los_hours\", stat='density');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "g = sns.FacetGrid(data=stops_df, col=\"PatType\", sharex=False);\n",
    "g.map(sns.histplot, \"los_hours\", stat='density', common_norm=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=stops_df, col=\"PatType\", sharex=False, sharey=False);\n",
    "g.map(sns.kdeplot, \"los_hours\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hm_oo]",
   "language": "python",
   "name": "conda-env-hm_oo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
