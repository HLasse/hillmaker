{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hillmaker - OO design ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall application design goals and objectives\n",
    "\n",
    "- should be easy to run a scenario and get all the standard outputs\n",
    "- scenario specific settings should be persistable as something like a json file\n",
    "- should be possible to generate only outputs wanted\n",
    "- should have a CLI\n",
    "- should be importable so that it can be used from notebook or other custom Python scripts\n",
    "- be nice to have a GUI for non-technie users\n",
    "- should be easy to explore multiple scenarios\n",
    "- global and scenario specific settings can be managed through settings files, command line args or function args\n",
    "- current occupancy, arrival and departure stats all still desirable\n",
    "- los summary would be nice\n",
    "- outputs should be in formats that lend themselves to further analysis and reporting such as csvs for the occ stats (bydatetime and summary), standard graphic file formats, perhaps JSON for los summary and occ stats\n",
    "- dataset profiling should be done to identify potential issues with horizon effects, warmup effects, missing data periods, or other anomolies.\n",
    "\n",
    "\n",
    "Should hillmaker be redesigned as an OO based application?\n",
    "\n",
    "- does OO design make for a better analyst experience? For example, does OO make it easier to create and manage a bunch of scenarios in which each is a separate hillmaker run? OO would make it easier to document scenarios through their settings (e.g. as json file).\n",
    "- does OO lead to potential performance gains by making it easier to only run the parts we want to run. For example, maybe we don't want individual day of week plots.\n",
    "- right now hillmaker is an (almost) all or nothing experience with each run standing alone. \n",
    "- OO would likely be better for those using hillmaker programmatically. \n",
    "- no matter what the design, there will always be a CLI.\n",
    "- not sure how OO or not affects GUI dev\n",
    "\n",
    "How should hillmaker be redesigned as an OO based application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other similar projects\n",
    "\n",
    "The [pandas-profiling](https://pandas-profiling.ydata.ai/docs/master/index.html) project has some similarities and has high quality code (certainly better than what I write).\n",
    "\n",
    "- Similar flow of doing analysis on a dataframe and producing various visualizations, reports, and other outputs\n",
    "- Produces plots, html reports, jupyter based report as well as providing results in json format\n",
    "- Uses pydantic to help with config settings management and input validation\n",
    "- Very focused use case - analyze dataframes\n",
    "- Very thorough documentation\n",
    "- The docs on [Changing Settings](https://pandas-profiling.ydata.ai/docs/master/pages/advanced_usage/changing_settings.html) is pretty much what we want to do (except don't need env vars option)\n",
    "- the CLI code is in console.py and it's the `Settings` class that sublclasses Pydantic's `BaseModel` class\n",
    "\n",
    "\n",
    "The [pyfolio](https://github.com/quantopian/pyfolio) project is also good for ideas.\n",
    "\n",
    "- financial analysis of a range of dates for a single stock - see tutorial at https://quantopian.github.io/pyfolio/notebooks/single_stock_example/\n",
    "- other more elaborate analyses\n",
    "- uses a `plotting.context` decorator function to allow plot customization. Matplotlib and seaborn support context managers for temporary changes to plot settings. The matplotlib context handles all the plot details whereas the Seaborn context manager is for higher level changes like plot scaling for different output targets such as notebook, paper or poster.\n",
    "\n",
    "An apache sniffer tool called [thrift](https://github.com/pinterest/thrift-tools)\n",
    "\n",
    "- simple, clean interface\n",
    "- CLI or library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 1 - overall and by patient type summaries\n",
    "\n",
    "Patients flow through a short stay unit for a variety of procedures, tests or therapies. Let's assume patients can be classified into one of five categories of patient types: ART (arterialgram), CAT (post cardiac-cath), MYE (myelogram), IVT (IV therapy), and OTH (other). From one of our hospital information systems we were able to get raw data about the entry and exit times of each patient and exported the data to a csv file. We call each row of such data a *stop* (as in, the patient stopped here for a while). \n",
    "\n",
    "- We want to generate summaries of occupancy as well as arrivals and discharges to go into a summary report for hospital administration. \n",
    "- We want these overall and by patient type. \n",
    "- We also want LOS summaries by patient type. \n",
    "- Volume and occupancy trends over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from IPython.display import Image\n",
    "\n",
    "from datetime import datetime, date\n",
    "from typing import Dict, List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssu_stopdata = '../data/ShortStay.csv'\n",
    "stops_df = pd.read_csv(ssu_stopdata, parse_dates=['InRoomTS','OutRoomTS'])\n",
    "stops_df.info() # Check out the structure of the resulting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new hills scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hillmaker as hm\n",
    "from hillmaker import hmlib as hmlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required inputs\n",
    "scenario_name = 'ss_example_1'\n",
    "in_field_name = 'InRoomTS'\n",
    "out_field_name = 'OutRoomTS'\n",
    "start_date = '1996-01-01'\n",
    "end_date = pd.Timestamp('9/30/1996')\n",
    "\n",
    "# Optional inputs\n",
    "\n",
    "cat_field_name = 'PatType'\n",
    "verbosity = 1 # INFO level logging\n",
    "output_path = './output'\n",
    "bin_size_minutes = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a `Scenario` class that is a Pydantic model. It handles a bunch of type constraints, validation, and default values. What does the `Scenario` class look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.Scenario??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create scenarios a few different ways.\n",
    "\n",
    "- instantiate an instance of `Scenario` by passing in keyword args\n",
    "- if the args are in a dict, can use dictionary unpacking to do the same\n",
    "- there's a `create_scenario` method that can take a dict, a TOML path or keyword args and returns a `Scenario` object (precedence is in the reverse order - kwargs get the final say)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1 = hm.Scenario(scenario_name=scenario_name, \n",
    "                         stops_df=stops_df,\n",
    "                         in_field=in_field_name,\n",
    "                         out_field=out_field_name,\n",
    "                         start_analysis_dt=start_date,\n",
    "                         end_analysis_dt=end_date,\n",
    "                         cat_field=cat_field_name,\n",
    "                         output_path=Path('./output'),\n",
    "                         verbosity=verbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need a pretty print method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(scenario_1.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use pydantic's `model_dump` function to create dictionary from a pydantic model. I'll do that and make a few changes and create a new scenario from the modified dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump pydantic model to dict (could wrap this with a to_dict() method\n",
    "scenario_2_dict = scenario_1.model_dump()\n",
    "\n",
    "# Make some changes\n",
    "scenario_2_dict['scenario_name'] = 'ss_example_2'\n",
    "scenario_2_dict['bin_size_minutes'] = 30\n",
    "\n",
    "# Make a new scenario\n",
    "scenario_2 = hm.Scenario(**scenario_2_dict)\n",
    "\n",
    "print(scenario_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the scenario objects are really just a Python class, attributes can be get and set in the usual way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.bin_size_minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is convenient, it does mean that as the programmer, you can get around some of the validation checks that were already done. For example, `bin_size_minutes` must evenly divide into 1440. I can add code to revalidate the model before allowing `make_hills` to run but I'm not going to bother for now. The standard Python error system will catch bad things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.bin_size_minutes = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate hills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.make_hills()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(scenario_1.hills['plots'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we'd want to be able to quickly view a specific plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added `get_plot()` as a method to the `Scenario` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = scenario_1.get_plot('occupancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.get_plot('occ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.get_plot('departures', 'Mon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required inputs\n",
    "scenario_name = 'ss_example_2'\n",
    "in_field_name = 'InRoomTS'\n",
    "out_field_name = 'OutRoomTS'\n",
    "start_date = '1996-01-01'\n",
    "end_date = pd.Timestamp('9/30/1996')\n",
    "\n",
    "# Optional inputs\n",
    "\n",
    "cat_field_name = 'PatType'\n",
    "verbosity = 1 # INFO level logging\n",
    "output_path = './output'\n",
    "bin_size_minutes = 60\n",
    "\n",
    "\n",
    "#df = pd.read_csv(file_stopdata, parse_dates=[in_field_name, out_field_name])\n",
    "\n",
    "hills_2 = hm.make_hills(scenario_name=scenario_name, stops_df=stops_df,\n",
    "              in_field=in_field_name, out_field=out_field_name,\n",
    "              start_analysis_dt=start_date, end_analysis_dt=end_date,\n",
    "              cat_field=cat_field_name,\n",
    "              bin_size_minutes=bin_size_minutes,\n",
    "              output_path='./output', verbosity=verbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = hm.get_plot(hills_2, scenario_name, 'o', 'week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['plots']['s202307251605_arrivals_plot_Tue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['bydatetime'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries']['nonstationary'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries']['stationary'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries']['nonstationary']['dow_binofday'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries']['stationary']['']['occupancy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 2 - partition patient types into two holding areas\n",
    "The hospital is considering sending some patient types to a new dedicated holding area. We want to be able to generate hillmaker outputs for various subsets of patients going to each of the two units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df['PatType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_subset = ['IVT', 'ART']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_subset = [type for type in stops_df['PatType'].unique() if type not in a_subset]\n",
    "b_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_holding_area(pat_type):\n",
    "    if pat_type in a_subset:\n",
    "        return 'unitA'\n",
    "    else:\n",
    "        return 'unitB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df['new_hold_area'] = stops_df['PatType'].map(lambda x: which_holding_area(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df['los'] = stops_df['OutRoomTS'] - stops_df['InRoomTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario02 = hm.HillsScenario(stops_df = stops_df, scenario_name = 'scenario02',\n",
    "                              in_field = in_field_name, out_field = out_field_name,\n",
    "                              start_analysis_dt = start_date, end_analysis_dt = end_date,\n",
    "                              cat_field = 'new_hold_area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario02.make_hills()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario02.hills['plots'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario02.hills['plots']['scenario02_occupancy_plot_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of an operational analysis we would like to compute a number of relevant statistics, such as:\n",
    "\n",
    "- mean and 95th percentile of overall SSU occupancy by hour of day and day of week,\n",
    "- similar hourly statistics for patient arrivals and departures,\n",
    "- all of the above but by patient type as well.\n",
    "\n",
    "In addition to tabular summaries, plots are needed. Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"images/ssu-occ.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hillmaker was designed for precisely this type of problem. In fact, the very first version of hillmaker was written for analyzing an SSU when the author was an undergraduate interning at a large health care system. That very first version was written in BASIC on a [DECwriter](https://en.wikipedia.org/wiki/DECwriter)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"images/DECwriter,_Tektronix,_PDP-11_(192826605).jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\">\n",
    "<font size=\"-2\">Source: By Wolfgang Stief from Tittmoning, Germany - DECwriter, Tektronix, PDP-11, CC0, https://commons.wikimedia.org/w/index.php?curid=105322423</font>\n",
    "</p>\n",
    "\n",
    "Over the years, hillmaker was migrated to [FoxPro](https://en.wikipedia.org/wiki/FoxPro), and then to MS Access where it [lived for many years](http://hillmaker.sourceforge.net/). In 2016, I [moved it to Python](https://misken.github.io/blog/hillmaker-python-released/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hm_oo]",
   "language": "python",
   "name": "conda-env-hm_oo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
