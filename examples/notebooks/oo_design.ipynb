{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hillmaker - OO design ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall application design goals and objectives\n",
    "\n",
    "- should be easy to run a scenario and get all the standard outputs\n",
    "- scenario specific settings should be persistable as something like a json file\n",
    "- should be possible to generate only outputs wanted\n",
    "- should have a CLI\n",
    "- should be importable so that it can be used from notebook or other custom Python scripts\n",
    "- be nice to have a GUI for non-technie users\n",
    "- should be easy to explore multiple scenarios\n",
    "- global and scenario specific settings can be managed through settings files, command line args or function args\n",
    "- current occupancy, arrival and departure stats all still desirable\n",
    "- los summary would be nice\n",
    "- outputs should be in formats that lend themselves to further analysis and reporting such as csvs for the occ stats (bydatetime and summary), standard graphic file formats, perhaps JSON for los summary and occ stats\n",
    "- dataset profiling should be done to identify potential issues with horizon effects, warmup effects, missing data periods, or other anomolies.\n",
    "\n",
    "\n",
    "Should hillmaker be redesigned as an OO based application?\n",
    "\n",
    "- does OO design make for a better analyst experience? For example, does OO make it easier to create and manage a bunch of scenarios in which each is a separate hillmaker run? OO would make it easier to document scenarios through their settings (e.g. as json file).\n",
    "- does OO lead to potential performance gains by making it easier to only run the parts we want to run. For example, maybe we don't want individual day of week plots.\n",
    "- right now hillmaker is an (almost) all or nothing experience with each run standing alone. \n",
    "- OO would likely be better for those using hillmaker programmatically. \n",
    "- no matter what the design, there will always be a CLI.\n",
    "- not sure how OO or not affects GUI dev\n",
    "\n",
    "How should hillmaker be redesigned as an OO based application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other similar projects\n",
    "\n",
    "The [pandas-profiling](https://pandas-profiling.ydata.ai/docs/master/index.html) project has some similarities and has high quality code (certainly better than what I write).\n",
    "\n",
    "- Similar flow of doing analysis on a dataframe and producing various visualizations, reports, and other outputs\n",
    "- Produces plots, html reports, jupyter based report as well as providing results in json format\n",
    "- Uses pydantic to help with config settings management and input validation\n",
    "- Very focused use case - analyze dataframes\n",
    "- Very thorough documentation\n",
    "- The docs on [Changing Settings](https://pandas-profiling.ydata.ai/docs/master/pages/advanced_usage/changing_settings.html) is pretty much what we want to do (except don't need env vars option)\n",
    "- the CLI code is in console.py and it's the `Settings` class that sublclasses Pydantic's `BaseModel` class\n",
    "\n",
    "\n",
    "The [pyfolio](https://github.com/quantopian/pyfolio) project is also good for ideas.\n",
    "\n",
    "- financial analysis of a range of dates for a single stock - see tutorial at https://quantopian.github.io/pyfolio/notebooks/single_stock_example/\n",
    "- other more elaborate analyses\n",
    "- uses a `plotting.context` decorator function to allow plot customization. Matplotlib and seaborn support context managers for temporary changes to plot settings. The matplotlib context handles all the plot details whereas the Seaborn context manager is for higher level changes like plot scaling for different output targets such as notebook, paper or poster.\n",
    "\n",
    "An apache sniffer tool called [thrift](https://github.com/pinterest/thrift-tools)\n",
    "\n",
    "- simple, clean interface\n",
    "- CLI or library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 1 - overall and by patient type summaries\n",
    "\n",
    "Patients flow through a short stay unit for a variety of procedures, tests or therapies. Let's assume patients can be classified into one of five categories of patient types: ART (arterialgram), CAT (post cardiac-cath), MYE (myelogram), IVT (IV therapy), and OTH (other). From one of our hospital information systems we were able to get raw data about the entry and exit times of each patient and exported the data to a csv file. We call each row of such data a *stop* (as in, the patient stopped here for a while). \n",
    "\n",
    "- We want to generate summaries of occupancy as well as arrivals and discharges to go into a summary report for hospital administration. \n",
    "- We want these overall and by patient type. \n",
    "- We also want LOS summaries by patient type. \n",
    "- Volume and occupancy trends over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from IPython.display import Image\n",
    "\n",
    "from datetime import datetime, date\n",
    "from typing import Dict, List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59877 entries, 0 to 59876\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   PatID      59877 non-null  int64         \n",
      " 1   InRoomTS   59877 non-null  datetime64[ns]\n",
      " 2   OutRoomTS  59877 non-null  datetime64[ns]\n",
      " 3   PatType    59877 non-null  object        \n",
      "dtypes: datetime64[ns](2), int64(1), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "ssu_stopdata = '../data/ShortStay.csv'\n",
    "stops_df = pd.read_csv(ssu_stopdata, parse_dates=['InRoomTS','OutRoomTS'])\n",
    "stops_df.info() # Check out the structure of the resulting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new hills scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'make_hills' from partially initialized module 'hillmaker' (most likely due to a circular import) (/home/mark/Documents/projects/hillmaker/src/hillmaker/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhillmaker\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhm\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhillmaker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hmlib \u001b[38;5;28;01mas\u001b[39;00m hmlib\n",
      "File \u001b[0;32m~/Documents/projects/hillmaker/src/hillmaker/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhillmaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhills\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_hills\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhillmaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhills\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Scenario\n",
      "File \u001b[0;32m~/Documents/projects/hillmaker/src/hillmaker/hills.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtomli\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtomllib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhillmaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscenario\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parameters\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhillmaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbydatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_bydatetime\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhillmaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummarize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summarize\n",
      "File \u001b[0;32m~/Documents/projects/hillmaker/src/hillmaker/scenario.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m from pydantic import BaseModel, field_validator, model_validator, confloat, FieldValidationInfo, ConfigDict\n\u001b[1;32m      9\u001b[0m \n\u001b[0;32m---> 10\u001b[0m from hillmaker import make_hills\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m try:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'make_hills' from partially initialized module 'hillmaker' (most likely due to a circular import) (/home/mark/Documents/projects/hillmaker/src/hillmaker/__init__.py)"
     ]
    }
   ],
   "source": [
    "import hillmaker as hm\n",
    "from hillmaker import hmlib as hmlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required inputs\n",
    "scenario_name = 'ss_example_1'\n",
    "in_field_name = 'InRoomTS'\n",
    "out_field_name = 'OutRoomTS'\n",
    "start_date = '1996-01-01'\n",
    "end_date = pd.Timestamp('9/30/1996')\n",
    "\n",
    "# Optional inputs\n",
    "\n",
    "cat_field_name = 'PatType'\n",
    "verbosity = 1 # INFO level logging\n",
    "output_path = './output'\n",
    "bin_size_minutes = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detour - playing with Pydantic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, ConfigDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scenario_pyd(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "    # Required parameters\n",
    "    scenario_name: str\n",
    "    stops_df: pd.DataFrame\n",
    "    in_field: str\n",
    "    out_field: str\n",
    "    # TODO - what if a pandas Timestamp or numpy datetime64 is passed in?\n",
    "    # See https://github.com/pydantic/pydantic/discussions/6972\n",
    "    start_analysis_dt: date | datetime | pd.Timestamp\n",
    "    end_analysis_dt: date | datetime | pd.Timestamp\n",
    "    # Optional parameters\n",
    "    cat_field: str = None\n",
    "    bin_size_minutes: int = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Scenario_pyd\nscenario_name\n  Field required [type=missing, input_value={'stops_df':        PatID... 'cat_field': 'PatType'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.1/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scenario_pyd_1 \u001b[38;5;241m=\u001b[39m \u001b[43mScenario_pyd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstops_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstops_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                              \u001b[49m\u001b[43min_field\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43min_field_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_field\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout_field_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mstart_analysis_dt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_analysis_dt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mcat_field\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcat_field_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hm_oo/lib/python3.10/site-packages/pydantic/main.py:159\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    158\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__pydantic_self__\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Scenario_pyd\nscenario_name\n  Field required [type=missing, input_value={'stops_df':        PatID... 'cat_field': 'PatType'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.1/v/missing"
     ]
    }
   ],
   "source": [
    "scenario_pyd_1 = Scenario_pyd(scenario_name = scenario_name,stops_df = stops_df, \n",
    "                              in_field = in_field_name, out_field = out_field_name,\n",
    "                              start_analysis_dt = start_date, end_analysis_dt = end_date,\n",
    "                              cat_field = cat_field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_pyd_1.bin_size_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1_dict = {'scenario_name': scenario_name, 'stops_df': stops_df, \n",
    "                   'in_field': in_field_name, 'out_field': out_field_name,\n",
    "                   'start_analysis_dt': start_date, 'end_analysis_dt': end_date,\n",
    "                   'cat_field': cat_field_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_pyd_2 = Scenario_pyd(**scenario_1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PatType'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_pyd_2.cat_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3190560422.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[25], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    **scenario_1_dict\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "**scenario_1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(start_date, pd.Timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(end_date, pd.Timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmlib.bin_of_analysis_range(np.datetime64('1996-01-01 12:30'), np.datetime64(start_date), bin_size_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1 = hm.Scenario(scenario_name = scenario_name, stops_df = stops_df, \n",
    "                              in_field = in_field_name, out_field = out_field_name,\n",
    "                              start_analysis_dt = start_date, end_analysis_dt = end_date,\n",
    "                              cat_field = cat_field_name, output_path = Path('./output/'))\n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need a pretty print method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(scenario_1.scenario_params.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(scenario_1.scenario_params.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(scenario_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.scenario_params.totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate hills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.make_hills()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(scenario_1.hills['plots'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we'd want to be able to quickly view a specific plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot(scenario_obj, flow_metric, day_of_week='week'):\n",
    "    flow_metric_str = flow_metric # Possibly allow abbreviations as inputs and then convert to full metric name\n",
    "    day_of_week_str = day_of_week # Again, need to decide on API to make easy on user\n",
    "    plot_name = f'{scenario_obj.scenario_params.scenario_name}_{flow_metric_str}_plot_{day_of_week_str}'\n",
    "    return scenario_obj.hills['plots'][plot_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(scenario_1, 'occupancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot(scenario_1, 'occupancy', 'Wed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added `get_plot()` as a method to the `Scenario` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.get_plot('occupancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.get_plot('occ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.get_plot('departures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['plots']['s202307251605_arrivals_plot_Tue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries']['nonstationary'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries']['nonstationary']['dow_binofday'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.hills['summaries']['nonstationary']['dow_binofday']['occupancy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 2 - partition patient types into two holding areas\n",
    "The hospital is considering sending some patient types to a new dedicated holding area. We want to be able to generate hillmaker outputs for various subsets of patients going to each of the two units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df['PatType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_subset = ['IVT', 'ART']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_subset = [type for type in stops_df['PatType'].unique() if type not in a_subset]\n",
    "b_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_holding_area(pat_type):\n",
    "    if pat_type in a_subset:\n",
    "        return 'unitA'\n",
    "    else:\n",
    "        return 'unitB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df['new_hold_area'] = stops_df['PatType'].map(lambda x: which_holding_area(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df['los'] = stops_df['OutRoomTS'] - stops_df['InRoomTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario02 = hm.HillsScenario(stops_df = stops_df, scenario_name = 'scenario02',\n",
    "                              in_field = in_field_name, out_field = out_field_name,\n",
    "                              start_analysis_dt = start_date, end_analysis_dt = end_date,\n",
    "                              cat_field = 'new_hold_area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario02.make_hills()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario02.hills['plots'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario02.hills['plots']['scenario02_occupancy_plot_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of an operational analysis we would like to compute a number of relevant statistics, such as:\n",
    "\n",
    "- mean and 95th percentile of overall SSU occupancy by hour of day and day of week,\n",
    "- similar hourly statistics for patient arrivals and departures,\n",
    "- all of the above but by patient type as well.\n",
    "\n",
    "In addition to tabular summaries, plots are needed. Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"images/ssu-occ.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hillmaker was designed for precisely this type of problem. In fact, the very first version of hillmaker was written for analyzing an SSU when the author was an undergraduate interning at a large health care system. That very first version was written in BASIC on a [DECwriter](https://en.wikipedia.org/wiki/DECwriter)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"images/DECwriter,_Tektronix,_PDP-11_(192826605).jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\">\n",
    "<font size=\"-2\">Source: By Wolfgang Stief from Tittmoning, Germany - DECwriter, Tektronix, PDP-11, CC0, https://commons.wikimedia.org/w/index.php?curid=105322423</font>\n",
    "</p>\n",
    "\n",
    "Over the years, hillmaker was migrated to [FoxPro](https://en.wikipedia.org/wiki/FoxPro), and then to MS Access where it [lived for many years](http://hillmaker.sourceforge.net/). In 2016, I [moved it to Python](https://misken.github.io/blog/hillmaker-python-released/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hm_oo]",
   "language": "python",
   "name": "conda-env-hm_oo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
