{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hillmaker - OO design ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall application design goals and objectives\n",
    "\n",
    "- should be easy to run a scenario and get all the standard outputs\n",
    "- scenario specific settings should be persistable as something like a json file\n",
    "- should be possible to generate only outputs wanted\n",
    "- should have a CLI\n",
    "- should be importable so that it can be used from notebook or other custom Python scripts\n",
    "- be nice to have a GUI for non-technie users\n",
    "- should be easy to explore multiple scenarios\n",
    "- global and scenario specific settings can be managed through settings files, command line args or function args\n",
    "- current occupancy, arrival and departure stats all still desirable\n",
    "- los summary would be nice\n",
    "- outputs should be in formats that lend themselves to further analysis and reporting such as csvs for the occ stats (bydatetime and summary), standard graphic file formats, perhaps JSON for los summary and occ stats\n",
    "- dataset profiling should be done to identify potential issues with horizon effects, warmup effects, missing data periods, or other anomolies.\n",
    "\n",
    "\n",
    "Should hillmaker be redesigned as an OO based application?\n",
    "\n",
    "- does OO design make for a better analyst experience? For example, does OO make it easier to create and manage a bunch of scenarios in which each is a separate hillmaker run? OO would make it easier to document scenarios through their settings (e.g. as json file).\n",
    "- does OO lead to potential performance gains by making it easier to only run the parts we want to run. For example, maybe we don't want individual day of week plots.\n",
    "- right now hillmaker is an (almost) all or nothing experience with each run standing alone. \n",
    "- OO would likely be better for those using hillmaker programmatically. \n",
    "- no matter what the design, there will always be a CLI.\n",
    "- not sure how OO or not affects GUI dev\n",
    "\n",
    "How should hillmaker be redesigned as an OO based application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other similar projects\n",
    "\n",
    "The [pandas-profiling](https://pandas-profiling.ydata.ai/docs/master/index.html) project has some similarities and has high quality code (certainly better than what I write).\n",
    "\n",
    "- Similar flow of doing analysis on a dataframe and producing various visualizations, reports, and other outputs\n",
    "- Produces plots, html reports, jupyter based report as well as providing results in json format\n",
    "- Uses pydantic to help with config settings management and input validation\n",
    "- Very focused use case - analyze dataframes\n",
    "- Very thorough documentation\n",
    "- The docs on [Changing Settings](https://pandas-profiling.ydata.ai/docs/master/pages/advanced_usage/changing_settings.html) is pretty much what we want to do (except don't need env vars option)\n",
    "- the CLI code is in console.py and it's the `Settings` class that sublclasses Pydantic's `BaseModel` class\n",
    "\n",
    "\n",
    "The [pyfolio](https://github.com/quantopian/pyfolio) project is also good for ideas.\n",
    "\n",
    "- financial analysis of a range of dates for a single stock - see tutorial at https://quantopian.github.io/pyfolio/notebooks/single_stock_example/\n",
    "- other more elaborate analyses\n",
    "- uses a `plotting.context` decorator function to allow plot customization. Matplotlib and seaborn support context managers for temporary changes to plot settings. The matplotlib context handles all the plot details whereas the Seaborn context manager is for higher level changes like plot scaling for different output targets such as notebook, paper or poster.\n",
    "\n",
    "An apache sniffer tool called [thrift](https://github.com/pinterest/thrift-tools)\n",
    "\n",
    "- simple, clean interface\n",
    "- CLI or library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime(\"%Y%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1440/62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1440 % 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def somefunc(**kwargs):\n",
    "    print(f'kwargs = {kwargs}')\n",
    "    print(f'type of kwargs is {type(kwargs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somefunc(a=1, b=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somefunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{} is False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 1 - overall and by patient type summaries\n",
    "\n",
    "Patients flow through a short stay unit for a variety of procedures, tests or therapies. Let's assume patients can be classified into one of five categories of patient types: ART (arterialgram), CAT (post cardiac-cath), MYE (myelogram), IVT (IV therapy), and OTH (other). From one of our hospital information systems we were able to get raw data about the entry and exit times of each patient and exported the data to a csv file. We call each row of such data a *stop* (as in, the patient stopped here for a while). \n",
    "\n",
    "- We want to generate summaries of occupancy as well as arrivals and discharges to go into a summary report for hospital administration. \n",
    "- We want these overall and by patient type. \n",
    "- We also want LOS summaries by patient type. \n",
    "- Volume and occupancy trends over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59877 entries, 0 to 59876\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   PatID      59877 non-null  int64         \n",
      " 1   InRoomTS   59877 non-null  datetime64[ns]\n",
      " 2   OutRoomTS  59877 non-null  datetime64[ns]\n",
      " 3   PatType    59877 non-null  object        \n",
      "dtypes: datetime64[ns](2), int64(1), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "ssu_stopdata = '../data/ShortStay.csv'\n",
    "stops_df = pd.read_csv(ssu_stopdata, parse_dates=['InRoomTS','OutRoomTS'])\n",
    "stops_df.info() # Check out the structure of the resulting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatID</th>\n",
       "      <th>InRoomTS</th>\n",
       "      <th>OutRoomTS</th>\n",
       "      <th>PatType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1996-01-01 07:44:00</td>\n",
       "      <td>1996-01-01 08:50:00</td>\n",
       "      <td>IVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1996-01-01 08:28:00</td>\n",
       "      <td>1996-01-01 09:20:00</td>\n",
       "      <td>IVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1996-01-01 11:44:00</td>\n",
       "      <td>1996-01-01 13:30:00</td>\n",
       "      <td>MYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1996-01-01 11:51:00</td>\n",
       "      <td>1996-01-01 12:55:00</td>\n",
       "      <td>CAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1996-01-01 12:10:00</td>\n",
       "      <td>1996-01-01 13:00:00</td>\n",
       "      <td>IVT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatID            InRoomTS           OutRoomTS PatType\n",
       "0      1 1996-01-01 07:44:00 1996-01-01 08:50:00     IVT\n",
       "1      2 1996-01-01 08:28:00 1996-01-01 09:20:00     IVT\n",
       "2      3 1996-01-01 11:44:00 1996-01-01 13:30:00     MYE\n",
       "3      4 1996-01-01 11:51:00 1996-01-01 12:55:00     CAT\n",
       "4      5 1996-01-01 12:10:00 1996-01-01 13:00:00     IVT"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new hills scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hillmaker as hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required inputs\n",
    "\n",
    "in_field_name = 'InRoomTS'\n",
    "out_field_name = 'OutRoomTS'\n",
    "start_date = '1996-01-01'\n",
    "end_date = pd.Timestamp('9/30/1996')\n",
    "\n",
    "# Optional inputs\n",
    "scenario_name = 'ss_example_1'\n",
    "cat_field_name = 'PatType'\n",
    "verbosity = 1 # INFO level logging\n",
    "output_path = './output'\n",
    "bin_size_minutes = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1 = hm.HillsScenario(stops_df = stops_df, \n",
    "                              in_field = in_field_name, out_field = out_field_name,\n",
    "                              start_analysis_dt = start_date, end_analysis_dt = end_date,\n",
    "                              cat_field = cat_field_name)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stops_df':        PatID            InRoomTS           OutRoomTS PatType\n",
      "0          1 1996-01-01 07:44:00 1996-01-01 08:50:00     IVT\n",
      "1          2 1996-01-01 08:28:00 1996-01-01 09:20:00     IVT\n",
      "2          3 1996-01-01 11:44:00 1996-01-01 13:30:00     MYE\n",
      "3          4 1996-01-01 11:51:00 1996-01-01 12:55:00     CAT\n",
      "4          5 1996-01-01 12:10:00 1996-01-01 13:00:00     IVT\n",
      "...      ...                 ...                 ...     ...\n",
      "59872  59873 1996-09-30 19:31:00 1996-09-30 20:15:00     IVT\n",
      "59873  59874 1996-09-30 20:23:00 1996-09-30 21:30:00     IVT\n",
      "59874  59875 1996-09-30 21:00:00 1996-09-30 22:45:00     CAT\n",
      "59875  59876 1996-09-30 21:57:00 1996-09-30 22:40:00     IVT\n",
      "59876  59877 1996-09-30 22:45:00 1996-09-30 23:35:00     CAT\n",
      "\n",
      "[59877 rows x 4 columns], 'in_field': 'InRoomTS', 'out_field': 'OutRoomTS', 'start_analysis_dt': datetime.date(1996, 1, 1), 'end_analysis_dt': datetime.date(1996, 9, 30), 'scenario_name': 's202209061714', 'cat_field': 'PatType', 'bin_size_minutes': 60, 'cats_to_exclude': None, 'percentiles': (0.25, 0.5, 0.75, 0.95, 0.99), 'occ_weight_field': None, 'totals': True, 'nonstationary_stats': True, 'stationary_stats': True, 'no_censored_departures': False, 'edge_bins': <EdgeBinsEnum.FRACTIONAL: 1>, 'output_path': PosixPath('.'), 'export_bydatetime_csv': True, 'export_summaries_csv': True, 'export_dow_png': False, 'export_week_png': False, 'cap': None, 'xlabel': None, 'ylabel': None, 'verbosity': <VerbosityEnum.WARNING: 0>}\n"
     ]
    }
   ],
   "source": [
    "print(scenario_1.scenario_params.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_1.scenario_params.totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.make_hills()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscenario_1_hills\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "scenario_1.hills.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the current hillmaker, here's what we would do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hillmaker as hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'InRoomTS' in stops_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "None in stops_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 2 - partition patient types into two holding areas\n",
    "The hospital is considering sending some patient types to a new dedicated holding area. We want to be able to generate hillmaker outputs for various subsets of patients going to each of the two units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Length of stay summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df['los'] = stops_df['OutRoomTS'] - stops_df['InRoomTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of an operational analysis we would like to compute a number of relevant statistics, such as:\n",
    "\n",
    "- mean and 95th percentile of overall SSU occupancy by hour of day and day of week,\n",
    "- similar hourly statistics for patient arrivals and departures,\n",
    "- all of the above but by patient type as well.\n",
    "\n",
    "In addition to tabular summaries, plots are needed. Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"images/ssu-occ.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hillmaker was designed for precisely this type of problem. In fact, the very first version of hillmaker was written for analyzing an SSU when the author was an undergraduate interning at a large health care system. That very first version was written in BASIC on a [DECwriter](https://en.wikipedia.org/wiki/DECwriter)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"images/DECwriter,_Tektronix,_PDP-11_(192826605).jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\">\n",
    "<font size=\"-2\">Source: By Wolfgang Stief from Tittmoning, Germany - DECwriter, Tektronix, PDP-11, CC0, https://commons.wikimedia.org/w/index.php?curid=105322423</font>\n",
    "</p>\n",
    "\n",
    "Over the years, hillmaker was migrated to [FoxPro](https://en.wikipedia.org/wiki/FoxPro), and then to MS Access where it [lived for many years](http://hillmaker.sourceforge.net/). In 2016, I [moved it to Python](https://misken.github.io/blog/hillmaker-python-released/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current (2022-07-19) status of code\n",
    "\n",
    "Version 0.4.3 was just released and is available on [PyPI](https://pypi.org/project/hillmaker/) or source from https://github.com/misken/hillmaker. This version is much faster than previous versions (thank you numpy) and includes a CLI that also supports TOML formatted config files, flow conservation checks and better logging. It does however revert back to only allowing a single category field (multiple category fields can easily be handled by constructing composite category strings). You can read more about this latest release of hillmaker at [https://misken.github.io/blog/hillmaker-python-released/](https://misken.github.io/blog/hillmaker-python-released/). It's free and open source.\n",
    "\n",
    "The new hillmaker is implemented as an importable Python module and as a runnable script with a simple CLI. This new version of hillmaker is still in what I'd call a pre-release state. The output does match the Access version for the ShortStay database that I included in the original Hillmaker. I've been actively using it to process thousands of simulation output log files as part of a research project on OB patient flow. More testing is needed before I release it as version 1.0, but it does appear to be doing its primary job correctly. Please open an issue on GitHub if you think it's computing something incorrectly. Before using for any real project work, you should do your own testing to confirm that it is working appropriately for your needs. Use at your own risk - see [LICENSE file in GitHub](https://github.com/misken/hillmaker/blob/master/LICENSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User interface plans\n",
    "Over the years, I (and many others) have used the old Hillmaker in a variety of ways, including:\n",
    "\n",
    "- MS Access form based GUI\n",
    "- run main Hillmaker sub from Access VBA Immediate Window\n",
    "- run Hillmaker main sub (and/or components subs) via custom VBA procedures\n",
    "\n",
    "I'd like users to be able to use the new Python based version in a number of different ways as well. As I'll show in this Jupyter notebook, it can be used by importing the `hillmaker` module and then calling hillmaker functions via:\n",
    "\n",
    "- a Jupyter notebook (or any Python terminal such as an IPython shell or QT console, or IDLE)\n",
    "- a Python script with the input arguments set and passed via Python statements\n",
    "\n",
    "### A CLI\n",
    "\n",
    "While these two options provide tons of flexibility for power users, I have also added a CLI. The CLI is demo'd in this notebook as well.\n",
    "\n",
    "### A GUI for hillmaker\n",
    "This is uncharted territory for me. Python has [a number of frameworks/toolkits for creating GUI apps](https://wiki.python.org/moin/GuiProgramming). This is not the highest priority for me but I do plan on creating a GUI for hillmaker. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Hillmaker\n",
    "\n",
    "Whereas the old Hillmaker required MS Access, the new one requires an installation of Python 3.7+ along with several Python modules that are widely used for analytics and data science work. The free and open source [Anaconda Distribution of Python](https://www.anaconda.com/products/distribution) is a great way to get started with Python for analytics work. It is available on all platforms. Once you've got a working version of Python, you can install into a Python (or Conda) virtual environment.\n",
    "\n",
    "**Option 1 - standard Python virtual environment**\n",
    "\n",
    "```\n",
    "$ pip install hillmaker\n",
    "```\n",
    "\n",
    "**Option 2 - conda Python virtual environment**\n",
    "\n",
    "```\n",
    "$ ~/anaconda3/envs/<conda venv name>/bin/python -m pip install hillmaker\n",
    "```\n",
    "\n",
    "The reason for the more convoluted install command when using conda virtual environments is that it turns out to be rather tricky to properly pip install something into a conda virtual environment. This is the source of much confusion and much discussion on StackOverflow. It boils down to making sure that you are using the `pip` executable **in your conda virtual environment** and **NOT** in your base conda environment. This [SO post](https://stackoverflow.com/questions/41060382/using-pip-to-install-packages-to-anaconda-environment/56889729#56889729) explains how the use of the `-m` flag helps in this regard. However, this post doesn't appear to mention that the same issue applies to the `python` executable itself. Again, you **MUST** make sure you are using the `python` executable in your conda virtual environment and not in your conda base environment. If you use Option 2 above, you'll be able to run the `hillmaker` script and its CLI and you'll also be able to import it if you wish to use hillmaker that way.\n",
    "\n",
    "Obviously if you are comfortable working with source code, you can also install `hillmaker` from its GitHub repo or a clone/fork of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module imports\n",
    "To run hillmaker we only need to import a few modules. Since the main hillmaker function uses pandas DataFrames for both data input and output, we need to import `pandas` in addition to `hillmaker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import hillmaker as hm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read main stop data file\n",
    "Here's the first few lines from our csv file containing the patient stop data:\n",
    "\n",
    "    PatID,InRoomTS,OutRoomTS,PatType\n",
    "    1,1/1/1996 7:44,1/1/1996 8:50,IVT\n",
    "    2,1/1/1996 8:28,1/1/1996 9:20,IVT\n",
    "    3,1/1/1996 11:44,1/1/1996 13:30,MYE\n",
    "    4,1/1/1996 11:51,1/1/1996 12:55,CAT\n",
    "    5,1/1/1996 12:10,1/1/1996 13:00,IVT\n",
    "    6,1/1/1996 14:16,1/1/1996 15:35,IVT\n",
    "    7,1/1/1996 14:40,1/1/1996 15:25,IVT\n",
    "\n",
    "\n",
    "We have already read this data into a pandas DataFrame named `stops_df`. Each record is a \"stop\" at the SSU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the top and bottom of `stops_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "stops_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "stops_df.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute some basic summary statistics such as the earliest and latest arrival and departure as well as counts by patient type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Earliest arrival = {stops_df[\"InRoomTS\"].min()}')\n",
    "print(f'Latest departure = {stops_df[\"OutRoomTS\"].max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df.groupby(['PatType'])['PatID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a sense of the number of patient visits by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df['InRoomTS'].groupby(stops_df.InRoomTS.dt.to_period(\"M\")).agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably want to do some length of stay analysis, so let's compute it in hours and then do `describe` by patient type. The plan is to add functions to hillmaker to do length of stay analysis automatically. In addition to statistical summaries as shown below, it would be nice to have histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df['LOS'] = (stops_df['OutRoomTS'] - stops_df['InRoomTS']) / pd.Timedelta(1, \"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df.groupby(['PatType'])['LOS'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating occupancy summaries\n",
    "The primary function in hillmaker is called `make_hills` and plays the same role as the `Hillmaker` function in the original Access VBA version of Hillmaker. Let's get a little help on this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(hm.make_hills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the parameters are similar to those in the original VBA version, though a few new ones have been added. For example, the `cat_to_exclude` parameter allows you to specify a list of category values for which you do not want occupancy statistics computed. Also, since the VBA version used an Access database as the container for its output, new parameters were added to control output to csv files instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create variables for the required inputs as well as a few of the optional inputs. \n",
    "\n",
    "* The `scenario` value gets used in creating output filenames. \n",
    "* The `in_field_name`, `out_field_name` and `cat_field_name` are all string variables used to specifiy the arrival time field, departure time field and patient category field, respectively.\n",
    "* The `start_date` and `end_date` are also strings that are capabile of being converted to a pandas Timestamp. There is no need to include times as hillmaker will include the entire end date automatically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **WARNING** - Horizon and warmup effects\n",
    "\n",
    "You need to be careful when specifying the start and end dates for your analysis (we call this the *analysis range*). You need to consider *horizon and warmup effects*. In the SSU example, each stop is just a few hours and there aren't any patients who arrive before 1/1/1996 are are still in the SSU on 1/1/1996. However, if we were working with data in which the stops are a few days in length (such as on an inpatient nursing unit), we need to think about what start date we should use and exactly how the original dataset was extracted. Hillmaker is completely capable of properly accounting for patients who arrive before the specified start date for the analysis as well as those who are discharged after the end date. However, it can only work with the stop data provided and you are responsible for considering warmup effects - a transient phase as occupancy builds to some stochastic steady state. Assume you know that you have stop data that was extracted, say, to include all patients discharged between 1/1/2021 and 12/30/2021 and that each stop might last for several days. You wouldn't want to set your hillmaker start date to 1/1/2021 as the system will appear to start out empty and occupancy will have a transient phase until the system fills to some sort of steady state. The longer the length of stay, the longer this warmup phase will take. You might want to experiment with start dates ranging from a few weeks to a few months **after** your earliest arrival time in your hillmaker stop data to see how long the system takes to reach a steady state. Similarly, if your criteria for selectng the stop data was discharges in 1/1/2021-12/30/2021, your data will **not** contain records for those patients admitted before 12/30/2021 but discharged after 12/30/2021. So, you might want to set your end date for hillmaker to be a few weeks before 12/20/2021.\n",
    "\n",
    "For our SSU data, we don't need to worry about this as patients only stay a few hours and the SSU typically only houses patients between ~6am-10pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Required inputs\n",
    "scenario = 'ss_example_1'\n",
    "in_field_name = 'InRoomTS'\n",
    "out_field_name = 'OutRoomTS'\n",
    "cat_field_name = 'PatType'\n",
    "start_date = '1/1/1996'\n",
    "end_date = '9/30/1996'\n",
    "\n",
    "# Optional inputs\n",
    "verbosity = 1 # INFO level logging\n",
    "output_path = './output'\n",
    "bin_size_minutes = 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll call the main `make_hills` function. In addition to capturing the return values we will also take the default behavior of having the summaries exported to csv files. You'll see that the filenames will contain the scenario string.\n",
    "\n",
    "Full week and day of week plots are created for arrivals, departures and occupancy (new in v0.4.4) and you can specify axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_ex1 = hm.make_hills(scenario, stops_df, in_field_name, out_field_name, \n",
    "                            start_date, end_date, cat_field_name, verbosity=verbosity, output_path=output_path,\n",
    "                            cap=55, export_dow_png=True, export_week_png=True,\n",
    "                            xlabel='hour', ylabel='ssu patients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of results dataframes (and exported csv files)\n",
    "\n",
    "There are two main types of output dataframes:\n",
    "\n",
    "* numbers of arrivals, departures and occupancy by datetime bin over the analysis range\n",
    "* statistical summaries of arrivals, departures, and occupancy over various datetime and category groupings\n",
    "\n",
    "The results dictionary is organized with these two types as the highest level keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digging into the `bydatetime` keys reveals that there is one DataFrame that is by datetime by category and one datetime DataFrame for the totals over all the category values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['bydatetime'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['bydatetime']['PatType_datetime'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['bydatetime']['PatType_datetime'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['bydatetime']['PatType_datetime'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['bydatetime']['PatType_datetime'].iloc[23:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the multi-index with one level for `PatType` and one level for the `datetime`, a `Timestamp`. Each row is one specific hour on a specific date in the analysis range. While `arrivals` and `departures` are integer values, `occupancy` can be fractional since patients may arrive and depart anywhere within a time bin and are given \"occupancy credit\" for the fraction of time they are present during that timebin.\n",
    "\n",
    "The other datetime DataFrame represents the overall totals (over all patient types). Notice that now the index is just a simple `DateTimeIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['bydatetime']['datetime'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['bydatetime']['datetime'].iloc[23:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a time series plot of occupancy over the entire date range is a good check that things make sense overall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Figure and Axes object\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "\n",
    "# Use datetime index as the X-axis values\n",
    "timestamps = results_ex1['bydatetime']['datetime'].index \n",
    "\n",
    "# Create series to plot\n",
    "occupancy = results_ex1['bydatetime']['datetime']['occupancy']\n",
    "\n",
    "# Styling of bars, lines, plot area\n",
    "\n",
    "# Style the bars for mean occupancy\n",
    "bar_color = 'grey'\n",
    "bar_opacity = 0.8\n",
    "\n",
    "# Set the background color of the plot. Argument is a string float in\n",
    "# (0,1) representing greyscale (0=black, 1=white)\n",
    "ax1.patch.set_facecolor('0.95')\n",
    "\n",
    "# Add data to the plot\n",
    "# Occupancy as bars \n",
    "ax1.bar(timestamps, occupancy, color=bar_color, alpha=bar_opacity, label='Occupancy')\n",
    "\n",
    "# Set plot and axis titles\n",
    "fig1.suptitle('Occupancy by hourly time bins', fontsize=28, fontweight='bold')\n",
    "ax1.set_title('All patient types', fontsize=24)\n",
    "ax1.set_xlabel('Time Bin', fontsize=14)\n",
    "ax1.set_ylabel('Patients', fontsize=14)\n",
    "\n",
    "# Gridlines\n",
    "ax1.grid(True, color='k')\n",
    "\n",
    "# Legend\n",
    "leg = ax1.legend(loc='best', frameon=True, fontsize=20)\n",
    "leg.get_frame().set_facecolor('white')\n",
    "\n",
    "# Plot size\n",
    "fig1.set_size_inches(16,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's dig into the summary dataframes. There are more of these as each metric - arrivals, departure, and occupancy, gets their own DataFrames. In addition, DataFrames are created for various groupings:\n",
    "\n",
    "- by category by day of week and time of day bin\n",
    "- totals over all category values by day of week and time of day bin\n",
    "- by category\n",
    "- totals over all category values\n",
    "\n",
    "The first two items are referred to as *nonstationary* summaries since the statistics are by day of week and time of day. The latter two items are *stationary* summaries as they are simply overall, time independent, statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['summaries'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['summaries']['nonstationary'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within each of these is a dictionary whose keys are flow metrics. To look at overall statistics (i.e. not by `PatType`) use the `'dow_binofday'` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['summaries']['nonstationary']['dow_binofday'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these three DataFrames has the same structure. We will focus on occupancy as it is the reason we are here. Notice that there are 168 rows in this dataframe, corresponding to the hours of the week. Of course, you can choose a different time bin size when running hillmaker. The multi-index contains day of week and time of bin of day levels in both integer string formats to facilitate plotting. \n",
    "\n",
    "Most of the column names are pretty self-explanatory:\n",
    "\n",
    "- `count` - number of occurances of this datetime bin in the analysis range\n",
    "- `mean` - mean occupancy in this datetime bin\n",
    "- `min` - minimum occupancy in this datetime bin\n",
    "- `max` - maximum occupancy in this datetime bin\n",
    "- `stdev` - standard deviation occupancy in this datetime bin\n",
    "- `sem` - standard error of mean occupancy in this datetime bin (`stdev / sqrt(mean)`)\n",
    "- `var` - variance of occupancy in this datetime bin (`stdev ** 2`)\n",
    "- `cv` - coefficient of variation of occupancy in this datetime bin (`stdev / mean`)\n",
    "- `skew` - skew of occupancy in this datetime bin\n",
    "- `kurtosis` - kurtosis of occupancy in this datetime bin\n",
    "- `p25` - 25th percentile of occupancy in this datetime bin\n",
    "- `p50` - 50th percentile (median) of occupancy in this datetime bin\n",
    "- `p75` - 75th percentile of occupancy in this datetime bin\n",
    "- `p95` - 95th percentile of occupancy in this datetime bin\n",
    "- `p99` - 99th percentile of occupancy in this datetime bin\n",
    "\n",
    "You can specify which percentiles are computed through the `percentiles` argument of the `make_hills` function. Those shown above are the default percentiles that are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['summaries']['nonstationary']['dow_binofday']['occupancy'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['summaries']['nonstationary']['dow_binofday']['occupancy'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the occupancy summary DataFrame, occupancy plots can be created. Here's a matplotlib approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>INFO</b> Plots are now automatically created by hillmaker using an updated version of the code below. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Figure and Axes object\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "\n",
    "# Create a list to use as the X-axis values\n",
    "num_bins = 7 * 1440 / bin_size_minutes\n",
    "base_date_for_first_dow = '01/05/2015' # Pick any date with associated DOW you want to appear first on plot\n",
    "timestamps = pd.date_range(base_date_for_first_dow, periods=num_bins, freq=f'{bin_size_minutes}Min').tolist()\n",
    "\n",
    "# Choose appropriate major and minor tick locations\n",
    "major_tick_locations = pd.date_range(f'{base_date_for_first_dow} 12:00:00', periods=7, freq='24H').tolist()\n",
    "minor_tick_locations = pd.date_range(f'{base_date_for_first_dow} 06:00:00', periods=42, freq='4H').tolist()\n",
    "\n",
    "# Set the tick locations for the axes object\n",
    "ax1.set_xticks(major_tick_locations)\n",
    "ax1.set_xticks(minor_tick_locations, minor=True)\n",
    "ax1.tick_params(which='both', direction='in')\n",
    "\n",
    "# Specify the mean occupancy and percentile values\n",
    "mean_occ = results_ex1['summaries']['nonstationary']['dow_binofday']['occupancy']['mean']\n",
    "pctile_occ = results_ex1['summaries']['nonstationary']['dow_binofday']['occupancy']['p95']\n",
    "\n",
    "# Styling of bars, lines, plot area\n",
    "# Style the bars for mean occupancy\n",
    "bar_color = 'grey'\n",
    "bar_opacity = 0.8\n",
    "\n",
    "# Style the line for the occupancy percentile\n",
    "pctile_line_style = '-'\n",
    "pctile_color = 'black'\n",
    "pctile_line_width = 1\n",
    "\n",
    "# Set the background color of the plot. Argument is a string float in\n",
    "# (0,1) representing greyscale (0=black, 1=white)\n",
    "ax1.patch.set_facecolor('0.95')\n",
    "\n",
    "# Add data to the plot\n",
    "# Mean occupancy as bars - here's the GOTCHA involving the bar width\n",
    "bar_width = 1 / (1440 / bin_size_minutes)\n",
    "ax1.bar(timestamps, mean_occ, color=bar_color, alpha=bar_opacity, label='Mean occupancy', width=bar_width)\n",
    "\n",
    "# Some percentile as a line\n",
    "ax1.plot(timestamps, pctile_occ, linestyle=pctile_line_style, linewidth=pctile_line_width, color=pctile_color, \\\n",
    "         label='95th %ile occupancy')\n",
    "\n",
    "# Create formatter variables\n",
    "dayofweek_formatter = DateFormatter('%a')\n",
    "qtrday_formatter = DateFormatter('%H')\n",
    "\n",
    "# Format the tick labels\n",
    "ax1.xaxis.set_major_formatter(dayofweek_formatter)\n",
    "ax1.xaxis.set_minor_formatter(qtrday_formatter)\n",
    "\n",
    "# Slide the major tick labels underneath the default location by 20 points\n",
    "ax1.tick_params(which='major', pad=25)\n",
    "\n",
    "# Add other chart elements\n",
    "\n",
    "# Set plot and axis titles\n",
    "fig1.suptitle('SSU Occupancy by Time of Day and Day of Week', fontsize=28, fontweight='bold')\n",
    "ax1.set_title('All patient types', fontsize=24)\n",
    "ax1.set_xlabel('Time Bin of Week', fontsize=14)\n",
    "ax1.set_ylabel('Patients', fontsize=14)\n",
    "\n",
    "# Gridlines\n",
    "ax1.grid(True, color='k')\n",
    "\n",
    "# Legend\n",
    "leg = ax1.legend(loc='best', frameon=True, fontsize=20)\n",
    "leg.get_frame().set_facecolor('white')\n",
    "\n",
    "# Plot size\n",
    "fig1.set_size_inches(16,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed plots by patient type can be created from the occupancy dataframe associated with the `'PatType_dow_binofday'` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ex1['summaries']['nonstationary']['PatType_dow_binofday']['occupancy'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataframe in the results dictionary can be exported to a csv file using the `export_bydatetime_csv` and `export_summaries_csv` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *nix\n",
    "!ls ./output/ss_example_1_*.csv\n",
    "# Windows\n",
    "# !dir .\\output\\ss_example_1_*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those csv files (and associated dataframes) not having `'dow_binofday'` in their name are stationary summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *nix\n",
    "!cat ./output/ss_example_1_occupancy.csv\n",
    "# Windows\n",
    "# !type .\\output\\ss_example_1_occupancy.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *nix\n",
    "!cat ./output/ss_example_1_occupancy_PatType.csv\n",
    "# Windows\n",
    "# !type .\\output\\ss_example_1_occupancy_PatType.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the stationary summaries, the `count` value of 6576 represents the total number of hourly time bins in the analysis range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days = (pd.Timestamp(end_date) - pd.Timestamp(start_date)) / pd.Timedelta(1, \"d\") + 1\n",
    "num_total_bins = num_days * 24\n",
    "print(f'Total number of hourly bins in analysis range: {num_total_bins:.0f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the CLI\n",
    "Instead of importing hillmaker and calling the `make_hills` function, you can also use its CLI. Not every input argument to `make_hills` is exposed in the CLI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hillmaker -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!hillmaker --scenario cli_test_ssu --stop_data_csv ../data/ShortStay.csv --in_field InRoomTS --out_field OutRoomTS --start_analysis_dt 1996-01-01 --end_analysis_dt 1996-09-30 --cat_field PatType --verbosity 1 --output_path output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using all those named command line arguments, you can also use a simple configuration file. I decided to use TOML for the configuration file format as it's very readable and only a quite simple configuration file is needed. Furthermore, TOML has been becoming more widely used in the Python community and a TOML parser will become part of the standard library in Python 3.11. For now, we can use the well known `tomli` library. Here's what the config file looks like. You'll notice it looks a bit like an INI file. See https://toml.io/en/ for more info on TOML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../ssu_example.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's just a simple way of grouping the command line arguments and specifying their values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hillmaker --config ../ssu_example.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More examples\n",
    "\n",
    "I will be creating additional examples to illustrate the capabilities of hillmaker. I will also write some actual documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hmoo]",
   "language": "python",
   "name": "conda-env-hmoo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
