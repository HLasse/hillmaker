{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version  0.15.2\n",
      "numpy version  1.9.2\n",
      "matplotlib version  1.4.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bydatetime\n",
    "import hillpylib\n",
    "from pandas import Timestamp\n",
    "\n",
    "# Let's check what version of pandas, numpy and matplotlib we are using\n",
    "print (\"pandas version \", pd.__version__)\n",
    "print (\"numpy version \", np.version.version)\n",
    "print (\"matplotlib version \", mp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up autoreloading of modules so that I can debug code in external files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it all together\n",
    "\n",
    "Below I've strung together all the pieces to do an entire Hillmaker run. Change inputs as needed (e.g. scenario_name and associated parameter values) and run all the cells below. You can skip rereading the main input file if that isn't changing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read main stop data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_stopdata = 'data/ShortStay.csv'\n",
    "df = pd.read_csv(file_stopdata, parse_dates=['InRoomTS','OutRoomTS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scenario_name = 'sstest_60'\n",
    "in_fld_name = 'InRoomTS'\n",
    "out_fld_name = 'OutRoomTS'\n",
    "cat_fld_name = 'PatType'\n",
    "start_analysis = '1/1/1996'\n",
    "end_analysis = '3/30/1996 23:45'\n",
    "bin_size_mins = 60\n",
    "\n",
    "# This next field wasn't in original Hillmaker. Use it to specify the name to use for the overall totals.\n",
    "# At this point the totals actually aren't being calculated.\n",
    "tot_fld_name = 'Total'\n",
    "\n",
    "## Convert string dates to actual datetimes\n",
    "start_analysis_dt = pd.Timestamp(start_analysis)\n",
    "end_analysis_dt = pd.Timestamp(end_analysis)\n",
    "\n",
    "# Mapper from weekday integer to string\n",
    "daynum_to_dayname = {0: 'Mon', 1: 'Tue', 2: 'Wed', 3: 'Thu', 4: 'Fri', 5: 'Sat', 6: 'Sun'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the by datetime table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rng_bydt created: 0.027539588000763615\n",
      "found unique categories: 0.03863483500026632\n",
      "Seeded bydatetime DataFrame created: 0.1175570940004036\n",
      "dayofweek, bin_of_day, bin_of_week computed: 0.4495099680007115\n",
      "Multi-index on bydatetime DataFrame created: 0.46274029400046857\n",
      "Multi-index fully lexsorted: 0.4935021390001566\n",
      "Num inner: 19795\n",
      "Done processing 19795 stop recs: 8.231990496000435\n"
     ]
    }
   ],
   "source": [
    "bydt_df = bydatetime.make_bydatetime(df,\n",
    "                                     in_fld_name,\n",
    "                                     out_fld_name,\n",
    "                                     cat_fld_name,\n",
    "                                     start_analysis_dt,\n",
    "                                     end_analysis_dt,\n",
    "                                     tot_fld_name,\n",
    "                                     bin_size_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category               object\n",
       "datetime       datetime64[ns]\n",
       "arrivals              float64\n",
       "departures            float64\n",
       "occupancy             float64\n",
       "day_of_week             int64\n",
       "bin_of_day              int64\n",
       "bin_of_week             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bydt_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_occstats(group, stub=''):\n",
    "    return {stub+'count': group.count(), stub+'mean': group.mean(), \n",
    "            stub+'min': group.min(),\n",
    "            stub+'max': group.max(), 'stdev': group.std(), \n",
    "            stub+'p50': group.quantile(0.5), stub+'p55': group.quantile(0.55),\n",
    "            stub+'p60': group.quantile(0.6), stub+'p65': group.quantile(0.65),\n",
    "            stub+'p70': group.quantile(0.7), stub+'p75': group.quantile(0.75),\n",
    "            stub+'p80': group.quantile(0.8), stub+'p85': group.quantile(0.85),\n",
    "            stub+'p90': group.quantile(0.9), stub+'p95': group.quantile(0.95),\n",
    "            stub+'p975': group.quantile(0.975), \n",
    "            stub+'p99': group.quantile(0.99)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bydt_dfgrp2 = bydt_df.groupby(['category','day_of_week','bin_of_day'])\n",
    "\n",
    "occ_stats = bydt_dfgrp2['occupancy'].apply(get_occstats)\n",
    "arr_stats = bydt_dfgrp2['arrivals'].apply(get_occstats)\n",
    "dep_stats = bydt_dfgrp2['departures'].apply(get_occstats)\n",
    "\n",
    "occ_stats_summary = occ_stats.unstack()\n",
    "arr_stats_summary = arr_stats.unstack()\n",
    "dep_stats_summary = dep_stats.unstack()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write summaries and by datetime out to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_bydt_csv = 'testing/bydate_' + scenario_name + '.csv'\n",
    "bydt_df.to_csv(file_bydt_csv, index=False)\n",
    "\n",
    "file_occ_csv = 'testing/occ_stats_' + scenario_name + '.csv'\n",
    "file_arr_csv = 'testing/arr_stats_' + scenario_name + '.csv'\n",
    "file_dep_csv = 'testing/dep_stats_' + scenario_name + '.csv'\n",
    "\n",
    "occ_stats_summary.to_csv(file_occ_csv)\n",
    "arr_stats_summary.to_csv(file_arr_csv)\n",
    "dep_stats_summary.to_csv(file_dep_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
