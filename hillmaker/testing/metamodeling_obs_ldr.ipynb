{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obs and LDR meta-modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Make the graphs a bit prettier, and bigger\n",
    "# pd.set_option('display.mpl_style', 'default') \n",
    "# pd.set_option('display.width', 5000) \n",
    "# pd.set_option('display.max_columns', 60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats, integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hillmaker as hm\n",
    "from pandas import Timestamp\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Read training data set\n",
    "train_df = pd.read_csv('train_exp9_tandem05_nodischadj.csv')\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by focusing on the OBS and LDR units. Since this part of the network uses recovery blocking, we can explore approximations for such systems. Also, from a practical point of view, getting blocked in OBS is an undesirable occurance. We can also do some basic sanity checking since OBS was modeled as (essentially) infinite capacity and exponential service. Thus, we have an $M/M/\\infty$ queue feeding an $M/E2/c_L$ queue. Furthermore, Scenarios 136-150 are infinite capacity: $M/M/\\infty --> M/E2/\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBS unit occupancy for infinite capacity scenarios\n",
    "Since $M/G/\\infty$ systems have Poisson occupancy, we can create a histogram of occupancy for one or more of the infinite capacity scenarios. The log files are at OU right now. However, we can at least look at means and variances of occupancy since they should be equal for Poisson distributions. Oops, hmout files are at OU too and like an idiot I didn't put occupancy sd's or variances into the results file. Doh!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_stopdata = './unit_stop_log_Experiment1_Scenario138_Rep17.csv'\n",
    "stops_df = pd.read_csv(file_stopdata)\n",
    "stops_df.info() # Check out the structure of the resulting DataFrame\n",
    "\n",
    "rx = re.compile(r'Scenario([0-9]{1,3})_Rep([0-9]{1,2})')\n",
    "\n",
    "m = re.search(rx, file_stopdata)\n",
    "scenario_name = m.group(0)\n",
    "scenario_num = m.group(1)\n",
    "rep_num = m.group(2)\n",
    "print (scenario_name, scenario_num, rep_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_fld_name = 'EnteredTS'\n",
    "out_fld_name = 'ExitedTS'\n",
    "cat_fld_name = 'Unit'\n",
    "start_analysis = '12/12/2015 00:00'\n",
    "end_analysis = '12/19/2016 00:00'\n",
    "\n",
    "# Optional inputs\n",
    "\n",
    "tot_fld_name = 'OBTot'\n",
    "bin_size_mins = 1\n",
    "#includecats = ['Obs', 'LDR', 'PP']\n",
    "outputpath = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basedate = Timestamp('20150215 00:00:00')\n",
    "stops_df['EnteredTS'] = stops_df.apply(lambda row:\n",
    "                                   Timestamp(round((basedate + pd.DateOffset(hours=row['Entered'])).value,-9)), axis=1)\n",
    "\n",
    "\n",
    "stops_df['ExitedTS'] = stops_df.apply(lambda row:\n",
    "                                  Timestamp(round((basedate + pd.DateOffset(hours=row['Exited'])).value,-9)), axis=1)\n",
    "\n",
    "# Filter stops data by start and end analysis dates\n",
    "start_analysis_dt = pd.Timestamp(start_analysis)\n",
    "end_analysis_dt = pd.Timestamp(end_analysis)\n",
    "\n",
    "stops_df = stops_df[(stops_df['EnteredTS'] <= end_analysis_dt) & (stops_df['ExitedTS'] >= start_analysis_dt)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create bydate table\n",
    "bydt = hm.bydatetime.make_bydatetime(stops_df,in_fld_name, out_fld_name,\n",
    "                         start_analysis,end_analysis,cat_fld_name,\n",
    "                         total_str=tot_fld_name,bin_size_minutes=bin_size_mins,\n",
    "                         edge_bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bydt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bydt.to_csv(\"bydt_minute.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs_occ = bydt.ix[bydt.category=='Obs','occupancy']\n",
    "ldr_occ = bydt.ix[bydt.category=='LDR','occupancy']\n",
    "pp_occ = bydt.ix[bydt.category=='PP','occupancy']\n",
    "\n",
    "obs_occ.to_csv(\"obs_occ.csv\")\n",
    "ldr_occ.to_csv(\"ldr_occ.csv\")\n",
    "pp_occ.to_csv(\"pp_occ.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obs_occ.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs_occ = pd.read_csv(\"obs_occ.csv\",header=None)\n",
    "ldr_occ = pd.read_csv(\"ldr_occ.csv\",header=None)\n",
    "pp_occ = pd.read_csv(\"pp_occ.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs_occ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    537121.000000\n",
       "mean          0.266858\n",
       "std           0.526885\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max           5.000000\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_occ[2].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    537121.000000\n",
       "mean          1.373270\n",
       "std           1.202208\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max           8.000000\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldr_occ[2].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4453041825604998"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldr_occ[2].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    537121.000000\n",
       "mean          6.278457\n",
       "std           2.739540\n",
       "min           0.000000\n",
       "25%           4.000000\n",
       "50%           6.000000\n",
       "75%           8.000000\n",
       "max          18.000000\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_occ[2].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.505081931933824"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_occ[2].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(pp_occ[2], kde=False, fit=stats.poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs_occ[(obs_occ > 0) & (obs_occ < 1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs_occ.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldr_occ.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp_occ.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run hillmaker\n",
    "hills = hm.make_hills(scenario_name,stops_df,in_fld_name, out_fld_name,\n",
    "                         start_analysis,end_analysis,cat_fld_name,\n",
    "                         total_str=tot_fld_name,bin_size_minutes=bin_size_mins,\n",
    "                         return_dataframes=True, export_path=outputpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hills.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bydt = hills['bydatetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(bydt.ix[bydt.category=='LDR','occupancy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bydt.ix[bydt.category=='LDR','occupancy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(bydt.ix[bydt.category=='PP','occupancy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bydt.ix[bydt.category=='PP','occupancy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2.343 ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, why aren't the occupancy stats suggestive of Pn distribution? Shouldn't mean occupancy = variance of occupancy? Does this have something to do with the way partial occupancy stats are done in hillmaker?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBS load vs occupancy scatter\n",
    "I already did these in R, but let's do them in Python using `matplotlib`, `seaborn`, and even y-hat's `ggplot` and, why not, `ggplot2` via RMagic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_infcap = train_df[train_df.scenario >= 136]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_infcap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib and Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "plt.scatter(train_infcap.load_obs,train_infcap.occ_mean_mean_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Seaborn\n",
    "sns.regplot(\"load_obs\",\"occ_mean_mean_obs\",data=train_infcap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_infcap.load_ldr,train_infcap.occ_mean_mean_ldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(\"load_ldr\",\"occ_mean_mean_ldr\",data=train_infcap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y-hat's ggplot and ggplot2 via RMagic\n",
    "Right now there seems to be issues with rpy2 on Python 3.5. Not sure about using Conda to install ggplot as it's not included and not sure about the stuff on anaconda.org. I could pip install it.\n",
    "\n",
    "http://eneskemalergin.github.io/2015/10/01/R_Magic_with_IPython/\n",
    "\n",
    "https://bitbucket.org/rpy2/rpy2/issues/313/typeerror-type-rpy2rinterfacestrsexpvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the extension - PROBLEMS RIGHT NOW WITH RPY2 ON PYTHON 3.5\n",
    "import rpy2.robjects.lib.ggplot2 as ggplot2\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%Rpush train_infcap\n",
    "%R str(train_infcap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ggplot(data=results_infcap) + aes(x=load_obs, y=occ_mean_mean_obs) + geom_point() + geom_abline()\n",
    "ggplot(data=results_infcap) + aes(x=load_ldr, y=occ_mean_mean_ldr) + geom_point() + geom_abline()\n",
    "ggplot(data=results_infcap) + aes(x=load_pp, y=occ_mean_mean_pp) + geom_point() + geom_abline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y-hat's ggplot\n",
    "\n",
    "ggplot(aes(x='load_ldr', y='occ_mean_mean_ldr'), data=train_infcap) + geom_point() + geom_abline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using my qng library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For now I'm just sticking qng.py into this directory\n",
    "import qng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "barber_arr = 1.37\n",
    "barber_svc = 1\n",
    "barber_c = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qng.mgc_prob_wait_erlangc(barber_arr, barber_svc, barber_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(qng.mgc_prob_wait_erlangc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_wait_ldr = [qng.mgc_prob_wait_erlangc(a,b,c) for (a,b,c) in zip(train_df.lam_ldr,1/train_df.alos_ldr,train_df.cap_ldr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_df.mean_pct_waitq_ldr,prob_wait_ldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_waitq_ldr_df = pd.DataFrame(dict(mean_pct_waitq_ldr=train_df.mean_pct_waitq_ldr,\n",
    "                                      prob_wait_ldr=prob_wait_ldr,\n",
    "                                      cap_ldr=train_df.cap_ldr,\n",
    "                                      cap_pp=train_df.cap_pp),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_waitq_ldr_df[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_waitq_ldr_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The short listing above shows the challenge. Each group of three scenarios have the same LDR capacity and birth volume and thus have the same value for predicted prob_wait_ldr based on a simple ErlangC approximation. However, the actual percentage that wait differs for the first three scenarios due to blocking in LDR for different PP capacity levels in the first three scenarios. This is good in the sense that it shows the problem is non-trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(qng.erlangc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ".2 * 72 + .8 * 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head(20)['actual_los_mean_mean_pp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the actual LDR alos values, we see that some are below 12 and some are higher than 12. One would think that the scenarios for which actual > 12 correspond to significant blocking in LDR and little queueing to get into LDR (since LDR LOS is reduced by queueing time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head(10)['actual_los_mean_mean_ldr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the actual mean LDR alos, how does erlangC do in predicting probability of waiting in obs to get into an LDR bed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_wait_ldr_approx = [qng.mgc_prob_wait_erlangc(a,b,c) for (a,b,c) \n",
    "                        in zip(train_df.lam_ldr,1/(train_df.actual_los_mean_mean_ldr/24.0),train_df.cap_ldr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_df.mean_pct_waitq_ldr,prob_wait_ldr_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, it performs quite well. So, need a good estimate of actual ALOS in LDR. That's tricky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_df.alos_ldr,train_df.actual_los_mean_mean_ldr/24.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_df.rho_pp,train_df.actual_los_mean_mean_ldr/24.0,c=train_df.rho_ldr)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='rho_pp',y='actual_los_mean_mean_ldr',data=train_df,hue='rho_ldr',fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is actual ALOS in LDR equal to planned LOS + average block time - average queue time? Don't have to worry about the discharge timing offset since this set of runs didn't do any adjustments for discharge timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['actual_los_mean_est_ldr'] = train_df['alos_ldr']*24.0 + \\\n",
    "    train_df['mean_blocked_by_pp_mean'] * train_df['mean_pct_blocked_by_pp'] * (1-train_df['tot_c_rate'])- \\\n",
    "    train_df['mean_waitq_ldr_mean'] * train_df['mean_pct_waitq_ldr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(y='actual_los_mean_mean_ldr',x='actual_los_mean_est_ldr',data=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postpartum\n",
    "Let's explore PP unit a bit. First of all, if we did an discharge timing adjustment, need to know how that changed the overall ALOS in PP. Feels like we could compute the bias from the discharge timing distribution as the difference from the middle of the day (t=12). For this set of runs with no discharge adjustment, actual and planned los should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alos_pp_lm1 = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train_df['planned_los_mean_mean_pp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = train_df['actual_los_mean_mean_pp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alos_pp_lm1.fit(X.reshape(-1,1),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(alos_pp_lm1.intercept_,alos_pp_lm1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(y='actual_los_mean_mean_pp',x='planned_los_mean_mean_pp',data=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [(a,b,c) for (a,b,c) \n",
    "                        in zip(train_df.lam_pp,1.0/(train_df.alos_pp),train_df.cap_pp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qng.mgc_prob_wait_erlangc(*params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_blocked_by_pp_approx = [qng.mgc_prob_wait_erlangc(a,b,c) for (a,b,c) \n",
    "                        in zip(train_df.lam_pp,1.0/(train_df.alos_pp),train_df.cap_pp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_blocked_by_pp_approx[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['mean_pct_blocked_by_pp'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['prob_blocked_by_pp_approx'] = pd.Series(prob_blocked_by_pp_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(y='mean_pct_blocked_by_pp',x='prob_blocked_by_pp_approx',data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train_df['mean_pct_blocked_by_pp'], kde=True, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train_df['prob_blocked_by_pp_approx'], kde=True, rug=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, why are these plots so different?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
